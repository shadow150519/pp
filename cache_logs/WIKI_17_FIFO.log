Cache: keySize: 4, valueSize: 688, dim: 172, capacity: 131072, maxQueryNum: 65536, deviceId: 0
has edge feature
total 110232 for train, can cache 131072, 1.1890558095652806%
Epoch 0:
save model at epoch 0
	train loss:130128.5726  val ap:0.871213  val auc:0.911594
	total time:272.686s sample time:46.188s prep time:222.841s
Epoch 1:
	train loss:77254.0903  val ap:0.855951  val auc:0.925742
	total time:269.866s sample time:46.558s prep time:220.622s
Epoch 2:
	train loss:68100.9047  val ap:0.863810  val auc:0.930922
	total time:258.916s sample time:44.283s prep time:212.191s
Epoch 3:
save model at epoch 3
	train loss:62532.7806  val ap:0.877940  val auc:0.934938
	total time:259.241s sample time:45.515s prep time:210.925s
Epoch 4:
save model at epoch 4
	train loss:58721.7257  val ap:0.887432  val auc:0.936901
	total time:263.785s sample time:46.278s prep time:215.142s
Epoch 5:
save model at epoch 5
	train loss:57473.4901  val ap:0.903464  val auc:0.943172
	total time:199.903s sample time:34.651s prep time:162.779s
Epoch 6:
save model at epoch 6
	train loss:56182.2042  val ap:0.906449  val auc:0.944039
	total time:169.957s sample time:29.272s prep time:138.544s
Epoch 7:
save model at epoch 7
	train loss:56143.4589  val ap:0.911717  val auc:0.945854
	total time:168.139s sample time:29.089s prep time:136.771s
Epoch 8:
save model at epoch 8
	train loss:54778.5393  val ap:0.914449  val auc:0.946371
	total time:168.271s sample time:29.248s prep time:136.703s
Epoch 9:
save model at epoch 9
	train loss:53845.1446  val ap:0.919813  val auc:0.948831
	total time:168.866s sample time:29.592s prep time:137.056s
Epoch 10:
save model at epoch 10
	train loss:52873.4494  val ap:0.922254  val auc:0.950020
	total time:168.251s sample time:29.741s prep time:135.843s
Epoch 11:
save model at epoch 11
	train loss:53190.8375  val ap:0.923343  val auc:0.950970
	total time:169.535s sample time:29.358s prep time:138.064s
Epoch 12:
save model at epoch 12
	train loss:52531.8598  val ap:0.923894  val auc:0.950435
	total time:169.220s sample time:30.123s prep time:136.810s
Epoch 13:
save model at epoch 13
	train loss:51688.3956  val ap:0.930038  val auc:0.953315
	total time:169.331s sample time:29.432s prep time:137.734s
Epoch 14:
save model at epoch 14
	train loss:51180.5756  val ap:0.933252  val auc:0.954438
	total time:169.929s sample time:29.754s prep time:138.133s
Epoch 15:
save model at epoch 15
	train loss:50628.3147  val ap:0.937100  val auc:0.957085
	total time:156.099s sample time:26.871s prep time:127.104s
Epoch 16:
save model at epoch 16
	train loss:49694.4882  val ap:0.943176  val auc:0.959647
	total time:146.463s sample time:25.770s prep time:118.190s
Epoch 17:
save model at epoch 17
	train loss:49139.6235  val ap:0.952306  val auc:0.964661
	total time:143.279s sample time:24.824s prep time:116.158s
Epoch 18:
save model at epoch 18
	train loss:48184.2600  val ap:0.956640  val auc:0.968114
	total time:143.117s sample time:25.193s prep time:115.553s
Epoch 19:
save model at epoch 19
	train loss:46839.2390  val ap:0.962762  val auc:0.972151
	total time:143.927s sample time:24.822s prep time:116.777s
Epoch 20:
save model at epoch 20
	train loss:46252.2857  val ap:0.964601  val auc:0.973950
	total time:144.508s sample time:25.168s prep time:117.138s
Epoch 21:
	train loss:44440.9539  val ap:0.963676  val auc:0.973599
	total time:132.071s sample time:22.630s prep time:106.955s
Epoch 22:
	train loss:44461.5303  val ap:0.964305  val auc:0.974390
	total time:114.266s sample time:20.000s prep time:92.484s
Epoch 23:
save model at epoch 23
	train loss:43857.2042  val ap:0.966820  val auc:0.975190
	total time:115.502s sample time:20.027s prep time:93.371s
Epoch 24:
save model at epoch 24
	train loss:43037.4504  val ap:0.969522  val auc:0.977278
	total time:84.615s sample time:14.354s prep time:68.790s
Epoch 25:
save model at epoch 25
	train loss:42197.1876  val ap:0.971927  val auc:0.978468
	total time:83.875s sample time:14.264s prep time:67.822s
Epoch 26:
	train loss:42208.4771  val ap:0.971678  val auc:0.978406
	total time:83.754s sample time:14.131s prep time:67.920s
Epoch 27:
save model at epoch 27
	train loss:41867.2510  val ap:0.972753  val auc:0.979902
	total time:101.158s sample time:17.131s prep time:81.901s
Epoch 28:
save model at epoch 28
	train loss:40925.6052  val ap:0.974147  val auc:0.980513
	total time:102.294s sample time:17.513s prep time:82.685s
Epoch 29:
save model at epoch 29
	train loss:40187.9099  val ap:0.975744  val auc:0.981569
	total time:101.835s sample time:17.468s prep time:82.174s
Epoch 30:
save model at epoch 30
	train loss:40068.6008  val ap:0.976046  val auc:0.981648
	total time:102.639s sample time:18.009s prep time:82.491s
Epoch 31:
save model at epoch 31
	train loss:39322.1084  val ap:0.976428  val auc:0.982265
	total time:92.023s sample time:15.979s prep time:74.141s
Epoch 32:
save model at epoch 32
	train loss:39003.9546  val ap:0.977084  val auc:0.982842
	total time:78.524s sample time:13.348s prep time:63.469s
Epoch 33:
save model at epoch 33
	train loss:38725.5840  val ap:0.979342  val auc:0.984213
	total time:91.411s sample time:15.607s prep time:73.799s
Epoch 34:
save model at epoch 34
	train loss:38216.9861  val ap:0.980098  val auc:0.984504
	total time:79.251s sample time:13.364s prep time:64.061s
Epoch 35:
save model at epoch 35
	train loss:37871.8747  val ap:0.980472  val auc:0.984766
	total time:67.462s sample time:11.301s prep time:54.729s
Epoch 36:
save model at epoch 36
	train loss:37006.2483  val ap:0.981167  val auc:0.985334
	total time:68.161s sample time:11.499s prep time:55.073s
Epoch 37:
	train loss:36979.4851  val ap:0.980768  val auc:0.984988
	total time:69.636s sample time:11.948s prep time:56.110s
Epoch 38:
save model at epoch 38
	train loss:36895.3813  val ap:0.981318  val auc:0.985096
	total time:75.733s sample time:12.957s prep time:61.096s
Epoch 39:
save model at epoch 39
	train loss:36670.2865  val ap:0.983324  val auc:0.986394
	total time:77.455s sample time:13.137s prep time:62.517s
Epoch 40:
	train loss:36217.5770  val ap:0.983074  val auc:0.986281
	total time:79.595s sample time:13.819s prep time:64.217s
Epoch 41:
	train loss:35764.7455  val ap:0.982616  val auc:0.986038
	total time:80.374s sample time:13.685s prep time:64.967s
Epoch 42:
save model at epoch 42
	train loss:35646.5952  val ap:0.983952  val auc:0.986890
	total time:62.570s sample time:10.582s prep time:50.551s
Epoch 43:
Traceback (most recent call last):
  File "/home/wtx/workspace/cpp_project/tgl/train_cache.py", line 295, in <module>
    ap, auc = eval('val')
  File "/home/wtx/workspace/cpp_project/tgl/train_cache.py", line 164, in eval
    aps.append(average_precision_score(y_true, y_pred))
  File "/home/wtx/miniconda3/envs/dgl/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/wtx/miniconda3/envs/dgl/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 268, in average_precision_score
    return _average_binary_score(
  File "/home/wtx/miniconda3/envs/dgl/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/wtx/miniconda3/envs/dgl/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 230, in _binary_uninterpolated_average_precision
    precision, recall, _ = precision_recall_curve(
  File "/home/wtx/miniconda3/envs/dgl/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 187, in wrapper
    return func(*args, **kwargs)
  File "/home/wtx/miniconda3/envs/dgl/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 952, in precision_recall_curve
    fps, tps, thresholds = _binary_clf_curve(
  File "/home/wtx/miniconda3/envs/dgl/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 810, in _binary_clf_curve
    assert_all_finite(y_score)
  File "/home/wtx/miniconda3/envs/dgl/lib/python3.10/site-packages/sklearn/utils/validation.py", line 200, in assert_all_finite
    _assert_all_finite(
  File "/home/wtx/miniconda3/envs/dgl/lib/python3.10/site-packages/sklearn/utils/validation.py", line 122, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/wtx/miniconda3/envs/dgl/lib/python3.10/site-packages/sklearn/utils/validation.py", line 171, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.
